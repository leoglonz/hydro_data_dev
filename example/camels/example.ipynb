{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMELS example:\n",
    "### See below for an example of how to format data using hydro_data_dev for camels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydro_data_dev as hdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Record(bucket='mhpi-spatial', dataset='camels', train_date_range=(datetime.datetime(1999, 10, 1, 0, 0), datetime.datetime(2008, 9, 30, 0, 0)), val_date_range=(datetime.datetime(2008, 10, 1, 0, 0), datetime.datetime(2014, 9, 30, 0, 0)), test_date_range=(datetime.datetime(1989, 10, 1, 0, 0), datetime.datetime(1999, 9, 30, 0, 0)), time_series_variables=['dayl_daymet', 'prcp_daymet', 'srad_daymet', 'tmean_daymet', 'vp_daymet'], target_variables=['runoff'], static_variables=['p_mean', 'pet_mean', 'p_seasonality', 'frac_snow', 'aridity', 'high_prec_freq', 'high_prec_dur', 'low_prec_freq', 'low_prec_dur', 'elev_mean', 'slope_mean', 'area_gages2', 'frac_forest', 'lai_max', 'lai_diff', 'gvf_max', 'gvf_diff', 'dom_land_cover_frac', 'dom_land_cover', 'root_depth_50', 'soil_depth_pelletier', 'soil_depth_statsgo', 'soil_porosity', 'soil_conductivity', 'max_water_content', 'sand_frac', 'silt_frac', 'clay_frac', 'geol_1st_class', 'glim_1st_class_frac', 'geol_2nd_class', 'glim_2nd_class_frac', 'carbonate_rocks_frac', 'geol_porostiy', 'geol_permeability'], station_ids=PosixPath('531_basin_list.txt'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = hdd.create_record(\"./example.yaml\")\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error opening the dataset: camels from mhpi-spatial",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/data/lgl5139/.conda/envs/hydrodl/lib/python3.11/site-packages/icechunk/__init__.py:132\u001b[0m, in \u001b[0;36mIcechunkStore.open_existing\u001b[0;34m(cls, storage, mode, config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mpyicechunk_store_open_existing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# TODO: we should have an exception type to catch here, for the case of non-existing repo\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Error fetching branch: ref error: `storage error `S3ListObjectError(DispatchFailure(DispatchFailure { source: ConnectorError { kind: Other(None), source: ResolveEndpointError { message: \"A region must be set when sending requests to S3.\", source: None }, connection: Unknown } }))``",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/data/lgl5139/project_blue_eyes/hydro_data_dev/src/hydro_data_dev/api/methods.py:41\u001b[0m, in \u001b[0;36mfetch_data\u001b[0;34m(record)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43micechunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIcechunkStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_existing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/data/lgl5139/.conda/envs/hydrodl/lib/python3.11/site-packages/icechunk/__init__.py:137\u001b[0m, in \u001b[0;36mIcechunkStore.open_existing\u001b[0;34m(cls, storage, mode, config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpyicechunk_store_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;66;03m# if the repo exists, this is an actual error we need to raise\u001b[39;00m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mValueError\u001b[0m: repository Error: ref error: `storage error `S3ListObjectError(DispatchFailure(DispatchFailure { source: ConnectorError { kind: Other(None), source: ResolveEndpointError { message: \"A region must be set when sending requests to S3.\", source: None }, connection: Unknown } }))``",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mhdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m ds\n",
      "File \u001b[0;32m/data/lgl5139/project_blue_eyes/hydro_data_dev/src/hydro_data_dev/api/methods.py:46\u001b[0m, in \u001b[0;36mfetch_data\u001b[0;34m(record)\u001b[0m\n\u001b[1;32m     41\u001b[0m     store \u001b[38;5;241m=\u001b[39m icechunk\u001b[38;5;241m.\u001b[39mIcechunkStore\u001b[38;5;241m.\u001b[39mopen_existing(\n\u001b[1;32m     42\u001b[0m         storage\u001b[38;5;241m=\u001b[39mstorage_config,\n\u001b[1;32m     43\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord\u001b[38;5;241m.\u001b[39mbucket\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     47\u001b[0m ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_zarr(store, zarr_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, consolidated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m station_ids \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mstation_ids\u001b[38;5;241m.\u001b[39mread_text()\u001b[38;5;241m.\u001b[39msplitlines()\n",
      "\u001b[0;31mValueError\u001b[0m: Error opening the dataset: camels from mhpi-spatial"
     ]
    }
   ],
   "source": [
    "ds = hdd.fetch_data(record=record)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydro_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
